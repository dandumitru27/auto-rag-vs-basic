{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a3f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\auto-rag-vs-basic\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:275: FutureWarning: You are using a Python version (3.10.11) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lightrag.llm.gemini import gemini_complete_if_cache, gemini_embed\n",
    "from lightrag.llm.openai import openai_complete_if_cache, openai_embed\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "from raganything import RAGAnything, RAGAnythingConfig\n",
    "\n",
    "provider = \"openai\"  # \"google_genai\" / \"openai\"\n",
    "\n",
    "if provider == \"google_genai\":\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "elif provider == \"openai\":\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d11cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RAGAnythingConfig(\n",
    "    working_dir=\"../rag_storage\",\n",
    "    parser=\"docling\",  # document parser (mineru or docling)\n",
    "    parse_method=\"txt\",  # auto/ocr/txt\n",
    "    enable_image_processing=False,\n",
    "    enable_table_processing=False,\n",
    "    enable_equation_processing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159aaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model_func(prompt, system_prompt=None, history_messages=None, **kwargs):\n",
    "    if history_messages is None:\n",
    "        history_messages = []\n",
    "\n",
    "    if provider == \"google_genai\":\n",
    "        return gemini_complete_if_cache(\n",
    "            \"gemini-2.5-flash\",\n",
    "            prompt,\n",
    "            system_prompt=system_prompt,\n",
    "            history_messages=history_messages,\n",
    "            api_key=api_key,\n",
    "            **kwargs,\n",
    "        )\n",
    "    elif provider == \"openai\":\n",
    "        return openai_complete_if_cache(\n",
    "            \"gpt-5-mini\",  # model name\n",
    "            prompt,\n",
    "            system_prompt=system_prompt,\n",
    "            history_messages=history_messages,\n",
    "            api_key=api_key,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d7b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if provider == \"google_genai\":\n",
    "    async def gemini_embedding(texts):\n",
    "        return await gemini_embed(\n",
    "            texts,\n",
    "            model=\"models/gemini-embedding-001\",\n",
    "            api_key=api_key,\n",
    "        )\n",
    "\n",
    "    embedding_func = EmbeddingFunc(\n",
    "        embedding_dim=768,\n",
    "        max_token_size=8192,\n",
    "        func=gemini_embedding,\n",
    "    )\n",
    "elif provider == \"openai\":\n",
    "    async def openai_embedding(texts):\n",
    "        return await openai_embed(\n",
    "            texts,\n",
    "            model=\"text-embedding-3-large\",\n",
    "            api_key=api_key,\n",
    "        )\n",
    "\n",
    "    embedding_func = EmbeddingFunc(\n",
    "        embedding_dim=3072,\n",
    "        max_token_size=8192,\n",
    "        func=openai_embedding,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a97192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: RAGAnything initialized with config:\n",
      "INFO:   Working directory: ../rag_storage\n",
      "INFO:   Parser: docling\n",
      "INFO:   Parse method: txt\n",
      "INFO:   Multimodal processing - Image: False, Table: False, Equation: False\n",
      "INFO:   Max concurrent files: 1\n"
     ]
    }
   ],
   "source": [
    "rag = RAGAnything(\n",
    "    config=config,\n",
    "    llm_model_func=llm_model_func,\n",
    "    embedding_func=embedding_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Parser 'docling' installation verified\n",
      "INFO: Initializing LightRAG with parameters: {'working_dir': '../rag_storage'}\n",
      "INFO: [] Created new empty graph file: ../rag_storage\\graph_chunk_entity_relation.graphml\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': '../rag_storage\\\\vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': '../rag_storage\\\\vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': '../rag_storage\\\\vdb_chunks.json'} 0 data\n",
      "INFO: [] Process 18364 KV load full_docs with 0 records\n",
      "INFO: [] Process 18364 KV load text_chunks with 0 records\n",
      "INFO: [] Process 18364 KV load full_entities with 0 records\n",
      "INFO: [] Process 18364 KV load full_relations with 0 records\n",
      "INFO: [] Process 18364 KV load entity_chunks with 0 records\n",
      "INFO: [] Process 18364 KV load relation_chunks with 0 records\n",
      "INFO: [] Process 18364 KV load llm_response_cache with 0 records\n",
      "INFO: [] Process 18364 doc status load doc_status with 0 records\n",
      "INFO: [] Process 18364 KV load parse_cache with 0 records\n",
      "INFO: Multimodal processors initialized with context support\n",
      "INFO: Available processors: ['generic']\n",
      "INFO: Context configuration: ContextConfig(context_window=1, context_mode='page', max_context_tokens=2000, include_headers=True, include_captions=True, filter_content_types=['text'])\n",
      "INFO: LightRAG, parse cache, and multimodal processors initialized\n",
      "INFO: Starting complete document processing: C:\\Dev\\EPO_Patent_PDFs\\EP11869524NWA1.pdf\n",
      "INFO: Starting document parsing: C:\\Dev\\EPO_Patent_PDFs\\EP11869524NWA1.pdf\n",
      "INFO: Using docling parser with method: txt\n",
      "INFO: Detected PDF file, using parser for PDF...\n",
      "INFO:raganything.parser:Docling command executed successfully\n",
      "INFO: Parsing C:\\Dev\\EPO_Patent_PDFs\\EP11869524NWA1.pdf complete! Extracted 1035 content blocks\n",
      "INFO: Stored parsing result in cache: f73798f345c2522212155d914bf113e1\n",
      "INFO: \n",
      "Content Information:\n",
      "INFO: * Total blocks in content_list: 1035\n",
      "INFO: * Content block types:\n",
      "INFO:   - text: 996\n",
      "INFO:   - image: 34\n",
      "INFO:   - table: 5\n",
      "INFO: Content separation complete:\n",
      "INFO:   - Text content length: 118385 characters\n",
      "INFO:   - Multimodal items count: 39\n",
      "INFO:   - Multimodal type distribution: {'image': 34, 'table': 5}\n",
      "INFO: Setting content source for context-aware multimodal processing...\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set for context extraction (format: minerU)\n",
      "INFO: Starting text content insertion into LightRAG...\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: EP11869524NWA1.pdf\n",
      "INFO: Processing d-id: doc-135e486963bd1ca6ea61510d9dfb0136\n",
      "INFO: Embedding func: 8 new workers initialized (Timeouts: Func: 30s, Worker: 60s, Health Check: 75s)\n",
      "ERROR: Embedding func: Error in decorated function for task 1880395523696_38151.921: Vector count mismatch: expected 8 vectors but got 16 vectors (from embedding result).\n",
      "ERROR: Traceback (most recent call last):\n",
      "  File \"c:\\Projects\\auto-rag-vs-basic\\.venv\\lib\\site-packages\\lightrag\\lightrag.py\", line 1895, in process_document\n",
      "    await asyncio.gather(*first_stage_tasks)\n",
      "  File \"c:\\Projects\\auto-rag-vs-basic\\.venv\\lib\\site-packages\\lightrag\\kg\\nano_vector_db_impl.py\", line 124, in upsert\n",
      "    embeddings_list = await asyncio.gather(*embedding_tasks)\n",
      "  File \"c:\\Projects\\auto-rag-vs-basic\\.venv\\lib\\site-packages\\lightrag\\utils.py\", line 503, in __call__\n",
      "    result = await self.func(*args, **kwargs)\n",
      "  File \"c:\\Projects\\auto-rag-vs-basic\\.venv\\lib\\site-packages\\lightrag\\utils.py\", line 1016, in wait_func\n",
      "    return await future\n",
      "  File \"c:\\Projects\\auto-rag-vs-basic\\.venv\\lib\\site-packages\\lightrag\\utils.py\", line 720, in worker\n",
      "    result = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\dandu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\dandu\\AppData\\Local\\Temp\\ipykernel_18364\\674549031.py\", line 16, in openai_embedding\n",
      "    return await openai_embed(\n",
      "  File \"c:\\Projects\\auto-rag-vs-basic\\.venv\\lib\\site-packages\\lightrag\\utils.py\", line 522, in __call__\n",
      "    raise ValueError(\n",
      "ValueError: Vector count mismatch: expected 8 vectors but got 16 vectors (from embedding result).\n",
      "\n",
      "ERROR: Failed to extract document 1/1: EP11869524NWA1.pdf\n",
      "INFO: Enqueued document processing pipeline stopped\n",
      "INFO: Text content insertion complete\n",
      "INFO: Starting multimodal content processing...\n",
      "INFO: Starting to process 39 multimodal content items\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No valid multimodal descriptions generated\n",
      "INFO: Multimodal content processing complete\n",
      "INFO: Document C:\\Dev\\EPO_Patent_PDFs\\EP11869524NWA1.pdf processing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Embedding func: Error in decorated function for task 1880395524320_38151.906: Vector count mismatch: expected 10 vectors but got 20 vectors (from embedding result).\n",
      "ERROR: Embedding func: Error in decorated function for task 1880395523280_38151.921: Vector count mismatch: expected 10 vectors but got 20 vectors (from embedding result).\n"
     ]
    }
   ],
   "source": [
    "await rag.process_document_complete(\n",
    "    file_path=\"C:\\\\Dev\\\\EPO_Patent_PDFs\\\\EP11869524NWA1.pdf\", output_dir=\"../output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65e37d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
