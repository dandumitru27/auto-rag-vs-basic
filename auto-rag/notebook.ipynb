{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a3f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\auto-rag-vs-basic\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:275: FutureWarning: You are using a Python version (3.10.11) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lightrag.llm.gemini import gemini_complete_if_cache, gemini_embed\n",
    "from lightrag.llm.openai import openai_complete_if_cache, openai_embed\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "from raganything import RAGAnything, RAGAnythingConfig\n",
    "\n",
    "provider = \"openai\"  # \"google_genai\" / \"openai\"\n",
    "\n",
    "if provider == \"google_genai\":\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "elif provider == \"openai\":\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d11cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RAGAnythingConfig(\n",
    "    working_dir=\"../rag_storage\",\n",
    "    parser=\"docling\",  # document parser (mineru or docling)\n",
    "    parse_method=\"txt\",  # auto/ocr/txt\n",
    "    enable_image_processing=False,\n",
    "    enable_table_processing=False,\n",
    "    enable_equation_processing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159aaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model_func(prompt, system_prompt=None, history_messages=None, **kwargs):\n",
    "    if history_messages is None:\n",
    "        history_messages = []\n",
    "\n",
    "    if provider == \"google_genai\":\n",
    "        return gemini_complete_if_cache(\n",
    "            \"gemini-2.5-flash\",\n",
    "            prompt,\n",
    "            system_prompt=system_prompt,\n",
    "            history_messages=history_messages,\n",
    "            api_key=api_key,\n",
    "            **kwargs,\n",
    "        )\n",
    "    elif provider == \"openai\":\n",
    "        return openai_complete_if_cache(\n",
    "            \"gpt-5-mini\",  # model name\n",
    "            prompt,\n",
    "            system_prompt=system_prompt,\n",
    "            history_messages=history_messages,\n",
    "            api_key=api_key,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d7b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "if provider == \"google_genai\":\n",
    "    async def gemini_embedding(texts):\n",
    "        return await gemini_embed(\n",
    "            texts,\n",
    "            model=\"models/gemini-embedding-001\",\n",
    "            api_key=api_key,\n",
    "        )\n",
    "\n",
    "    embedding_func = EmbeddingFunc(\n",
    "        embedding_dim=768,\n",
    "        max_token_size=8192,\n",
    "        func=gemini_embedding,\n",
    "    )\n",
    "elif provider == \"openai\":\n",
    "    client = AsyncOpenAI(api_key=api_key)\n",
    "\n",
    "    async def openai_embedding(texts):\n",
    "        single_input = isinstance(texts, str)\n",
    "        if single_input:\n",
    "            texts = [texts]\n",
    "\n",
    "        resp = await client.embeddings.create(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            input=texts,\n",
    "        )\n",
    "        \n",
    "        data_sorted = sorted(resp.data, key=lambda r: r.index)\n",
    "        matrix = np.asarray([row.embedding for row in data_sorted], dtype=np.float32)\n",
    "\n",
    "        if matrix.shape[0] != len(texts):\n",
    "            raise ValueError(\n",
    "                f\"Vector count mismatch: expected {len(texts)} vectors but got {matrix.shape[0]} vectors.\"\n",
    "            )\n",
    "\n",
    "        # Return 1D for single text, 2D for batch\n",
    "        return matrix[0] if single_input else matrix\n",
    "\n",
    "    embedding_func = EmbeddingFunc(\n",
    "        embedding_dim=3072,\n",
    "        max_token_size=8192,\n",
    "        func=openai_embedding,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a97192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: RAGAnything initialized with config:\n",
      "INFO:   Working directory: ../rag_storage\n",
      "INFO:   Parser: docling\n",
      "INFO:   Parse method: txt\n",
      "INFO:   Multimodal processing - Image: False, Table: False, Equation: False\n",
      "INFO:   Max concurrent files: 1\n"
     ]
    }
   ],
   "source": [
    "rag = RAGAnything(\n",
    "    config=config,\n",
    "    llm_model_func=llm_model_func,\n",
    "    embedding_func=embedding_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd3eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Parser 'docling' installation verified\n",
      "INFO: Initializing LightRAG with parameters: {'working_dir': '../rag_storage'}\n",
      "INFO: [] Loaded graph from ../rag_storage\\graph_chunk_entity_relation.graphml with 23 nodes, 25 edges\n",
      "INFO:nano-vectordb:Load (23, 3072) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': '../rag_storage\\\\vdb_entities.json'} 23 data\n",
      "INFO:nano-vectordb:Load (25, 3072) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': '../rag_storage\\\\vdb_relationships.json'} 25 data\n",
      "INFO:nano-vectordb:Load (1, 3072) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': '../rag_storage\\\\vdb_chunks.json'} 1 data\n",
      "INFO: [] Process 23236 KV load full_docs with 1 records\n",
      "INFO: [] Process 23236 KV load text_chunks with 1 records\n",
      "INFO: [] Process 23236 KV load full_entities with 1 records\n",
      "INFO: [] Process 23236 KV load full_relations with 1 records\n",
      "INFO: [] Process 23236 KV load entity_chunks with 23 records\n",
      "INFO: [] Process 23236 KV load relation_chunks with 25 records\n",
      "INFO: [] Process 23236 KV load llm_response_cache with 4 records\n",
      "INFO: [] Process 23236 doc status load doc_status with 1 records\n",
      "INFO: [] Process 23236 KV load parse_cache with 1 records\n",
      "INFO: Multimodal processors initialized with context support\n",
      "INFO: Available processors: ['generic']\n",
      "INFO: Context configuration: ContextConfig(context_window=1, context_mode='page', max_context_tokens=2000, include_headers=True, include_captions=True, filter_content_types=['text'])\n",
      "INFO: LightRAG, parse cache, and multimodal processors initialized\n",
      "INFO: Starting complete document processing: C:\\Dev\\EPO_Patent_PDFs\\EP11869524NWA1.pdf\n",
      "INFO: Starting document parsing: C:\\Dev\\EPO_Patent_PDFs\\EP11869524NWA1.pdf\n",
      "INFO: Using docling parser with method: txt\n",
      "INFO: Detected PDF file, using parser for PDF...\n",
      "INFO:raganything.parser:Docling command executed successfully\n",
      "INFO: Parsing C:\\Dev\\EPO_Patent_PDFs\\EP11869524NWA1.pdf complete! Extracted 1035 content blocks\n",
      "INFO: Stored parsing result in cache: f73798f345c2522212155d914bf113e1\n",
      "INFO: \n",
      "Content Information:\n",
      "INFO: * Total blocks in content_list: 1035\n",
      "INFO: * Content block types:\n",
      "INFO:   - text: 996\n",
      "INFO:   - image: 34\n",
      "INFO:   - table: 5\n",
      "INFO: Content separation complete:\n",
      "INFO:   - Text content length: 118385 characters\n",
      "INFO:   - Multimodal items count: 39\n",
      "INFO:   - Multimodal type distribution: {'image': 34, 'table': 5}\n",
      "INFO: Setting content source for context-aware multimodal processing...\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set for context extraction (format: minerU)\n",
      "INFO: Starting text content insertion into LightRAG...\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: EP11869524NWA1.pdf\n",
      "INFO: Processing d-id: doc-135e486963bd1ca6ea61510d9dfb0136\n",
      "INFO: Embedding func: 8 new workers initialized (Timeouts: Func: 30s, Worker: 60s, Health Check: 75s)\n",
      "INFO: LLM func: 4 new workers initialized (Timeouts: Func: 180s, Worker: 360s, Health Check: 375s)\n",
      "INFO:  == LLM cache == saving: default:extract:b29362a91d06c80dfd4a355db2ebe70f\n",
      "INFO:  == LLM cache == saving: default:extract:511a2ba7abcc20c4fe9324b37d076e80\n",
      "INFO:  == LLM cache == saving: default:extract:0780143106debfdfae1da60ab9c74d68\n",
      "INFO:  == LLM cache == saving: default:extract:a791b1155aaf2e71c7455ee0f4a256bd\n",
      "INFO:  == LLM cache == saving: default:extract:ce5f64e9b0a90870d80886b374060d06\n",
      "INFO: Chunk 1 of 28 extracted 25 Ent + 27 Rel chunk-a9b8b89350e78edba844293630e29c0f\n",
      "INFO:  == LLM cache == saving: default:extract:abad4e0a0a2defe83339816dc53d8c0c\n",
      "INFO: Chunk 2 of 28 extracted 41 Ent + 46 Rel chunk-cf641a9f8b54bdaf2dac221675d59e8e\n",
      "INFO:  == LLM cache == saving: default:extract:fd9fd15d0aa4927ae0de340b01e4c68a\n",
      "INFO: Chunk 3 of 28 extracted 42 Ent + 47 Rel chunk-2112dd345226a464f34d76544b5db59b\n",
      "INFO:  == LLM cache == saving: default:extract:b970c3db51427a3b74e8e4d810870d53\n",
      "INFO:  == LLM cache == saving: default:extract:b444058f5dfa92d93c0063e71e09b750\n",
      "INFO: Chunk 4 of 28 extracted 51 Ent + 44 Rel chunk-a8655387d0d60e93120e7bc22a3fb22d\n",
      "INFO:  == LLM cache == saving: default:extract:897c6e545300e69495b661c800ae8fdc\n",
      "INFO:  == LLM cache == saving: default:extract:84eab8ee78fb181d6afc466e78189473\n",
      "INFO:  == LLM cache == saving: default:extract:541517c786a2d0bf3b80431f8b0c93ea\n",
      "INFO: Chunk 5 of 28 extracted 29 Ent + 30 Rel chunk-162e00bb12fa20c426c0e8d90041cf35\n",
      "INFO:  == LLM cache == saving: default:extract:543683d02bc551ffbc43e35e0a7e5ee4\n",
      "INFO: Chunk 6 of 28 extracted 32 Ent + 33 Rel chunk-269734cdf26c2667d7b2883ea6d38366\n",
      "INFO:  == LLM cache == saving: default:extract:2fb1aa2a0cb94d241f08b429c1da857c\n",
      "INFO:  == LLM cache == saving: default:extract:293d665e73169dbe279907dee4d2e438\n",
      "INFO: Chunk 7 of 28 extracted 31 Ent + 39 Rel chunk-d2e8e9e955bee9f47734d669c98d084d\n",
      "INFO:  == LLM cache == saving: default:extract:3827913d9514048af0a4981371ac0412\n",
      "INFO:  == LLM cache == saving: default:extract:41ade8d825520e33a2d37046ef6dcaa6\n",
      "INFO: Chunk 8 of 28 extracted 26 Ent + 35 Rel chunk-b3a360be57db8b58dcc13d574d547f71\n",
      "INFO:  == LLM cache == saving: default:extract:fce6f5f237787f9caec1225e3c09bdcc\n",
      "INFO: Chunk 9 of 28 extracted 22 Ent + 22 Rel chunk-0fc6e19ba6a922cf7815086f10a59460\n",
      "INFO:  == LLM cache == saving: default:extract:72f3d3b8a56392dafa1ed0255f63df20\n",
      "INFO:  == LLM cache == saving: default:extract:f32d3df8e5492dafeea819509e3616d1\n",
      "INFO:  == LLM cache == saving: default:extract:25f8e9aead2835fbb6bda49e12642a74\n",
      "INFO:  == LLM cache == saving: default:extract:7e6e31e79934effbbaadf599bd7092ab\n",
      "INFO: Chunk 10 of 28 extracted 25 Ent + 26 Rel chunk-eae0e01184e34a7041b8fabad4ec5102\n",
      "INFO:  == LLM cache == saving: default:extract:edb9ad8c71021fdcaf1913c2b65386a7\n",
      "INFO:  == LLM cache == saving: default:extract:0a75c633ce8fb0fe19812388ddfc7629\n",
      "INFO: Chunk 11 of 28 extracted 28 Ent + 35 Rel chunk-e60d30ff1444a1a1a96a9d388af65e7a\n",
      "INFO:  == LLM cache == saving: default:extract:79e0b81899f46cc04fd77dca939b0955\n",
      "INFO: Chunk 12 of 28 extracted 23 Ent + 31 Rel chunk-e712d21c634c417898431cde4ec8d84c\n",
      "INFO:  == LLM cache == saving: default:extract:c5ccbd36c90bb4e510eb07d1ad56ff0b\n",
      "INFO:  == LLM cache == saving: default:extract:b2f11457d7776335292cfedd94c96bfe\n",
      "INFO: Chunk 13 of 28 extracted 28 Ent + 31 Rel chunk-a036f8f86e7521d2b97abe6daff44b14\n",
      "INFO:  == LLM cache == saving: default:extract:aa0e3143b7910fbbe06ce2af1310f4dd\n",
      "INFO: Chunk 14 of 28 extracted 21 Ent + 27 Rel chunk-f49967df64377eea1e8515437e4cc158\n",
      "INFO:  == LLM cache == saving: default:extract:7397b30e938e2c90f7d6ef1ab823d2f2\n",
      "INFO:  == LLM cache == saving: default:extract:fd4d824068f91c2f86752d3bf14a0b11\n",
      "INFO:  == LLM cache == saving: default:extract:f9b7e71bb985c3dd50379bd87aaa93f9\n",
      "INFO:  == LLM cache == saving: default:extract:9864cfd411f8d978836e59e717134c36\n",
      "INFO:  == LLM cache == saving: default:extract:e0d3aae264f927634a4af568cb648341\n",
      "INFO: Chunk 15 of 28 extracted 24 Ent + 30 Rel chunk-795e74ebb345bc1ca06b92af9591a1e4\n",
      "INFO:  == LLM cache == saving: default:extract:02273141fb5cc12b2c661770185885b4\n",
      "INFO: Chunk 16 of 28 extracted 27 Ent + 29 Rel chunk-efe7c35e3d911e06a9bbfd9af5a15568\n",
      "INFO:  == LLM cache == saving: default:extract:203c5bb46b0e1afb1d3be738a752d480\n",
      "INFO: Chunk 17 of 28 extracted 24 Ent + 25 Rel chunk-21f7e6b977d978c2699b98125f5736c7\n",
      "INFO:  == LLM cache == saving: default:extract:27fea40f2924fec5b98164798ccbf74f\n",
      "INFO: Chunk 18 of 28 extracted 30 Ent + 37 Rel chunk-5ad0caca44632f0fef846a387f3ba1f2\n",
      "INFO:  == LLM cache == saving: default:extract:f95f99a1875b9e4c2edab4ce542d5361\n",
      "INFO:  == LLM cache == saving: default:extract:d6f6a141e69b1790e5f176b1317af3d7\n",
      "INFO:  == LLM cache == saving: default:extract:234eac930586e314dca1dc2b86039526\n",
      "INFO:  == LLM cache == saving: default:extract:4d70ab26876c5f4156ce6d0de9406f34\n",
      "INFO:  == LLM cache == saving: default:extract:6d70a0bb65a7c91809ea82603f2a6a3a\n",
      "INFO: Chunk 19 of 28 extracted 27 Ent + 33 Rel chunk-40ea6dde1ba4bee15f904c72007b7075\n",
      "INFO:  == LLM cache == saving: default:extract:ad86f65653d6903eb34a3af46eedacb1\n",
      "INFO: Chunk 20 of 28 extracted 32 Ent + 30 Rel chunk-46f8dc0197036619d9158f7ef25aa40e\n",
      "INFO:  == LLM cache == saving: default:extract:77caa270abf4c526592ac4e74538381f\n",
      "INFO: Chunk 21 of 28 extracted 19 Ent + 26 Rel chunk-f1a6aa7205c71d9cab4adb5e142e799a\n",
      "INFO:  == LLM cache == saving: default:extract:95321f8df767461d9b6508ecf2bf4dde\n",
      "INFO: Chunk 22 of 28 extracted 21 Ent + 24 Rel chunk-226f68773f09ebd433a5f6a69bc494e1\n",
      "INFO:  == LLM cache == saving: default:extract:e8368145f6dafdfc6d95ccfb11018518\n",
      "INFO:  == LLM cache == saving: default:extract:0585705cf371ac347df3696e65be4b65\n",
      "INFO:  == LLM cache == saving: default:extract:7d0d61fb60f1e8ce39ce287362f8bf8c\n",
      "INFO:  == LLM cache == saving: default:extract:e29048417de96389fe8feb3bf81237c7\n",
      "INFO: Chunk 23 of 28 extracted 16 Ent + 19 Rel chunk-5401c96a4a7a5832fb9584053465074a\n",
      "INFO:  == LLM cache == saving: default:extract:7ff416aeec033467d75ad2abec5db922\n",
      "INFO:  == LLM cache == saving: default:extract:c51eceb7815e9e0ff5a533bcaf7a19b0\n",
      "INFO: Chunk 24 of 28 extracted 19 Ent + 25 Rel chunk-d08bfb6ade9c523f950f931d7cc634ec\n",
      "INFO:  == LLM cache == saving: default:extract:034ad0ea4e443058132edcd8858af551\n",
      "INFO: Chunk 25 of 28 extracted 27 Ent + 22 Rel chunk-b9013e8bc04d041bfae02784a54acc8b\n",
      "INFO:  == LLM cache == saving: default:extract:e99c34267c3274124827850d53c5affc\n",
      "INFO: Chunk 26 of 28 extracted 28 Ent + 32 Rel chunk-a68fb21548e989716cd2edd5288cfc65\n",
      "INFO:  == LLM cache == saving: default:extract:359554b70cfe767e5abd368e4bb079a9\n",
      "INFO:  == LLM cache == saving: default:extract:873c928430f5128f3931bb2eef3af52a\n",
      "INFO:  == LLM cache == saving: default:extract:b06e3d82c0567cc9634b0d330f4eb637\n",
      "INFO: Chunk 27 of 28 extracted 25 Ent + 27 Rel chunk-323854923eb2e792cafc7e0f75bee9f6\n",
      "INFO:  == LLM cache == saving: default:extract:406edaf78696156cfe77d8d66bc5abdc\n",
      "INFO: Chunk 28 of 28 extracted 33 Ent + 28 Rel chunk-b2d99131347bbb2642cbeda48408edf1\n",
      "INFO: Merging stage 1/1: EP11869524NWA1.pdf\n",
      "INFO: Phase 1: Processing 434 entities from doc-135e486963bd1ca6ea61510d9dfb0136 (async: 8)\n",
      "INFO:  == LLM cache == saving: default:summary:d3866af30e19c651ccc07ca32b31a188\n",
      "INFO: LLMmrg: `Lighting Control Unit 15` | 0+8\n",
      "INFO:  == LLM cache == saving: default:summary:b81d6ba960442dcc8cd56265426eb51b\n",
      "INFO: LLMmrg: `Light Source Panel 10` | 0+8\n",
      "INFO:  == LLM cache == saving: default:summary:68b964fb91f4a8036e3e1bc012035b7a\n",
      "INFO: LLMmrg: `Vehicle 1` | 0+16\n",
      "INFO:  == LLM cache == saving: default:summary:a970d0de35f7bc226a959337f7d1ac32\n",
      "INFO: LLMmrg: `ECU 14` | 0+15\n",
      "INFO:  == LLM cache == saving: default:summary:e2186d8fe1738857a06eb16a704a985e\n",
      "INFO: LLMmrg: `Support Information` | 0+13\n",
      "INFO:  == LLM cache == saving: default:summary:462984740464a125ff56e6f97d2949fa\n",
      "INFO: LLMmrg: `Optical Stimulus` | 0+18\n",
      "INFO:  == LLM cache == saving: default:summary:cf399b0958d4e7de81e385fadb2ce6cb\n",
      "INFO: LLMmrg: `Driver` | 0+20\n",
      "INFO:  == LLM cache == saving: default:summary:cd7509af5baf374a04e4846ba55a77b2\n",
      "INFO: LLMmrg: `Object 2` | 0+8\n",
      "INFO:  == LLM cache == saving: default:summary:256355f05b6a94c22f3662965f2a3e54\n",
      "INFO: LLMmrg: `Lighting Pattern` | 0+9\n",
      "INFO:  == LLM cache == saving: default:summary:70ecd9fe62a913e4d55a84bcab7ed36f\n",
      "INFO: LLMmrg: `Virtual Image 31` | 0+10\n",
      "INFO:  == LLM cache == saving: default:summary:2c4560a94d71487807f1997ba033b7a3\n",
      "INFO: LLMmrg: `Degree Of Risk` | 0+10\n",
      "INFO: Phase 2: Processing 734 relations from doc-135e486963bd1ca6ea61510d9dfb0136 (async: 8)\n",
      "INFO:  == LLM cache == saving: default:summary:c6bfa0e1e6c5f2815b41217dcd3d5cb5\n",
      "INFO: LLMmrg: `Driver`~`Support Information` | 0+8\n",
      "INFO: Phase 3: Updating final 436(434+2) entities and  734 relations from doc-135e486963bd1ca6ea61510d9dfb0136\n",
      "INFO: Completed merging: 434 entities, 2 extra entities, 734 relations\n",
      "INFO: [] Writing graph with 459 nodes, 759 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed processing file 1/1: EP11869524NWA1.pdf\n",
      "INFO: Enqueued document processing pipeline stopped\n",
      "INFO: Text content insertion complete\n",
      "INFO: Document doc-135e486963bd1ca6ea61510d9dfb0136 text processing is complete, but multimodal content still needs processing\n",
      "INFO: Starting multimodal content processing...\n",
      "INFO: Starting to process 39 multimodal content items\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: image\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No processor found for type: table\n",
      "WARNING: No valid multimodal descriptions generated\n",
      "INFO: Multimodal content processing complete\n",
      "INFO: Document C:\\Dev\\EPO_Patent_PDFs\\EP11869524NWA1.pdf processing complete!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:\\\\Dev\\\\EPO_Patent_PDFs\\\\EP11869524NWA1.pdf\"\n",
    "# file_path = \"..\\\\pdf\\\\returul_unui_produs.pdf\"\n",
    "\n",
    "await rag.process_document_complete(file_path, output_dir=\"../output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f710bb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing text query: Cum vor fi rambursati banii?...\n",
      "INFO: Query mode: mix\n",
      "INFO:  == LLM cache == saving: mix:keywords:0bf408b51c70a374a32852272f2c2b72\n",
      "INFO: Query nodes: Refund method, Bank transfer, Credit card refund, Processing time, Transaction ID, Refund amount (top_k:40, cosine:0.2)\n",
      "INFO: Local query: 21 entites, 25 relations\n",
      "INFO: Query edges: Refund process, Money reimbursement, Refund policy, Refund timeline (top_k:40, cosine:0.2)\n",
      "INFO: Global query: 23 entites, 25 relations\n",
      "INFO: Naive query: 1 chunks (chunk_top_k:20 cosine:0.2)\n",
      "INFO: Raw search results: 23 entities, 25 relations, 1 vector chunks\n",
      "INFO: After truncation: 23 entities, 25 relations\n",
      "INFO: Selecting 1 from 1 entity-related chunks by vector similarity\n",
      "INFO: Find no additional relations-related chunks from 25 relations\n",
      "INFO: Round-robin merged chunks: 2 -> 1 (deduplicated 1)\n",
      "WARNING: Rerank is enabled but no rerank model is configured. Please set up a rerank model or set enable_rerank=False in query parameters.\n",
      "INFO: Final context: 23 entities, 25 relations, 1 chunks\n",
      "INFO: Final chunks S+F/O: E23/1\n",
      "INFO:  == LLM cache == saving: mix:query:160c0088bcb12e8e20f5c58697574609\n",
      "INFO: Text query completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Rambursarea banilor\n",
      "\n",
      "- **Metoda de rambursare:** Suma va fi restituită, în mod normal, prin aceeași metodă de plată folosită la plasarea comenzii. Dacă ai solicitat altfel, rambursarea se poate face conform cererii tale.  \n",
      "- **Plăți online cu cardul:** În cazul plăților efectuate online cu cardul, suma este returnată direct în contul bancar asociat cardului utilizat.  \n",
      "- **Termen:** Contravaloarea produsului returnat va fi rambursată în termen de **14 zile calendaristice** de la confirmarea aprobării returului.  \n",
      "- **Confirmarea aprobării returului:** Rambursarea este inițiată după ce returul este aprobat (după verificarea produselor de către echipă, conform procedurii de retur).\n",
      "\n",
      "### References\n",
      "\n",
      "- [1] returul_unui_produs.pdf\n"
     ]
    }
   ],
   "source": [
    "answer = await rag.aquery(\"Cum vor fi rambursati banii?\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
